# core/ai_engine.py - Enhanced Version by C (æ¶æ„å¸ˆ)
"""
Cognitive Black Box - ä¼˜åŒ–åçš„AIå¼•æ“
è§£å†³ä¸ªæ€§åŒ–å·¥å…·ç”Ÿæˆä¸­çš„æ¨¡æ¿å˜é‡é—®é¢˜å’Œè´¨é‡é—®é¢˜
"""

import streamlit as st
import asyncio
import os
import time
import json
import re
from typing import Dict, Any, Optional, Tuple, List
from datetime import datetime
from pathlib import Path
import logging

# AI API imports with error handling
try:
    import google.generativeai as genai
    from anthropic import Anthropic
    APIS_AVAILABLE = True
except ImportError:
    APIS_AVAILABLE = False
    st.warning("AI API libraries not installed. Running in fallback mode.")

class EnhancedAIEngine:
    """
    ğŸ”§ ä¼˜åŒ–åçš„AIå¼•æ“ - è§£å†³ä¸ªæ€§åŒ–è´¨é‡é—®é¢˜
    
    ä¸»è¦æ”¹è¿›ï¼š
    1. æ™ºèƒ½å˜é‡æ›¿æ¢ç³»ç»Ÿ
    2. å¢å¼ºçš„ä¸ªæ€§åŒ–promptå·¥ç¨‹
    3. é«˜è´¨é‡é™çº§æœºåˆ¶
    4. ç”¨æˆ·è¾“å…¥æ™ºèƒ½åˆ†æ
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.config = self._load_config()
        self.roles = self._load_roles()
        self.response_cache = {}
        self.performance_metrics = {}
        
        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        self._initialize_ai_clients()
        
        # ğŸ”§ æ–°å¢ï¼šä¸ªæ€§åŒ–åˆ†æå™¨
        self.personalization_analyzer = PersonalizationAnalyzer()
        
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½AIå¼•æ“é…ç½®"""
        return {
            'max_response_time': 8.0,  # ä¼˜åŒ–åçš„è¶…æ—¶è®¾ç½®
            'cache_ttl': 3600,
            'max_retries': 2,
            'fallback_enabled': True,
            'api_config': {
                'gemini': {
                    'model': 'gemini-2.5-pro', 
                    'temperature': 0.7, 
                    'max_tokens': 2048
                }
            }
        }
    
    def _load_roles(self) -> Dict[str, Any]:
        """åŠ è½½AIè§’è‰²é…ç½®"""
        roles = {}
        try:
            from config import load_prompt_config
            
            role_ids = ['host', 'investor', 'mentor', 'assistant']
            for role_id in role_ids:
                role_config = load_prompt_config(role_id)
                if role_config:
                    roles[role_id] = AIRole(role_id, role_config)
                    
        except Exception as e:
            self.logger.error(f"Failed to load roles: {e}")
            
        return roles
    
    def _initialize_ai_clients(self):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        self.gemini_client = None
        self.claude_client = None
        
        if APIS_AVAILABLE:
            try:
                # åˆå§‹åŒ–Gemini
                api_key = os.getenv('GEMINI_API_KEY')
                if api_key:
                    genai.configure(api_key=api_key)
                    self.gemini_client = genai.GenerativeModel('gemini-2.5-pro')
                    
                # åˆå§‹åŒ–Claude
                claude_key = os.getenv('ANTHROPIC_API_KEY')
                if claude_key:
                    self.claude_client = Anthropic(api_key=claude_key)
                    
            except Exception as e:
                self.logger.error(f"Failed to initialize AI clients: {e}")
    
    def generate_response(self, role_id: str, user_input: str, context: Dict[str, Any]) -> Tuple[str, bool]:
        """
        ğŸ”§ å¢å¼ºçš„å“åº”ç”Ÿæˆ - æ ¸å¿ƒä¼˜åŒ–æ–¹æ³•
        
        æ”¹è¿›ï¼š
        1. æ™ºèƒ½ä¸ªæ€§åŒ–åˆ†æ
        2. é«˜è´¨é‡promptæ„å»º
        3. å®Œç¾çš„é™çº§æœºåˆ¶
        """
        try:
            # ğŸ”§ Step 1: åˆ†æç”¨æˆ·ä¸ªæ€§åŒ–æ•°æ®
            personalization_data = self.personalization_analyzer.analyze_user_context(context)
            
            # ğŸ”§ Step 2: æ„å»ºé«˜è´¨é‡prompt
            enhanced_prompt = self._build_enhanced_prompt(role_id, user_input, context, personalization_data)
            
            # ğŸ”§ Step 3: å°è¯•AIç”Ÿæˆ
            if self.gemini_client and role_id == 'assistant':
                ai_response = self._call_gemini_api(enhanced_prompt)
                if ai_response and self._validate_response_quality(ai_response, context):
                    return ai_response, True
            
            # ğŸ”§ Step 4: é«˜è´¨é‡é™çº§
            fallback_response = self._generate_enhanced_fallback(role_id, context, personalization_data)
            return fallback_response, True
            
        except Exception as e:
            self.logger.error(f"Error in generate_response: {e}")
            return self._generate_enhanced_fallback(role_id, context, {}), False
    
    def _build_enhanced_prompt(self, role_id: str, user_input: str, context: Dict[str, Any], 
                             personalization_data: Dict[str, Any]) -> str:
        """
        ğŸ”§ æ„å»ºå¢å¼ºçš„ä¸ªæ€§åŒ–prompt
        """
        role = self.roles.get(role_id)
        if not role:
            return ""
            
        # è·å–ç”¨æˆ·è¾“å…¥æ•°æ®
        user_system_name = context.get('user_system_name', 'é«˜çº§å†³ç­–å®‰å…¨ç³»ç»Ÿ')
        user_core_principle = context.get('user_core_principle', 'æƒå¨è¶Šå¼ºï¼Œè¶Šè¦éªŒè¯')
        user_decisions = context.get('user_decisions', {})
        
        # æ„å»ºä¸ªæ€§åŒ–prompt
        if role_id == 'assistant':
            prompt = f"""
ä½ æ˜¯ä¸“ä¸šçš„é«˜çº§æ‰§è¡ŒåŠ©ç†ï¼Œä¸ºç”¨æˆ·åˆ›å»ºä¸ªæ€§åŒ–çš„å†³ç­–å®‰å…¨ç³»ç»Ÿã€‚

ç”¨æˆ·èƒŒæ™¯åˆ†æï¼š
- å†³ç­–é£æ ¼ï¼š{personalization_data.get('decision_style', 'å¹³è¡¡å‹')}
- é£é™©åå¥½ï¼š{personalization_data.get('risk_preference', 'é€‚ä¸­')}
- ä¸»è¦å†³ç­–ï¼š{personalization_data.get('key_decision', 'æœªçŸ¥')}

ç”¨æˆ·è¾“å…¥ï¼š
- ç³»ç»Ÿåç§°ï¼š{user_system_name}
- æ ¸å¿ƒåŸåˆ™ï¼š{user_core_principle}

è¯·åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„ä¸ªæ€§åŒ–å†³ç­–å®‰å…¨ç³»ç»Ÿï¼ŒåŒ…æ‹¬ï¼š
1. ç³»ç»Ÿæ¦‚è¿°ï¼ˆä½¿ç”¨ç”¨æˆ·çš„ç³»ç»Ÿåç§°ï¼‰
2. æ ¸å¿ƒåŸåˆ™ï¼ˆåŸºäºç”¨æˆ·è¾“å…¥ï¼‰
3. å››ç»´éªŒè¯çŸ©é˜µ
4. ä¸ªæ€§åŒ–é¢„è­¦ç³»ç»Ÿ
5. å®æ–½æŒ‡å¯¼

è¦æ±‚ï¼š
- å¿…é¡»ä½¿ç”¨ç”¨æˆ·æä¾›çš„ç³»ç»Ÿåç§°å’Œæ ¸å¿ƒåŸåˆ™
- å†…å®¹è¦å…·ä½“å®ç”¨ï¼Œä¸è¦ä½¿ç”¨å ä½ç¬¦
- åŸºäºç”¨æˆ·çš„å†³ç­–é£æ ¼è¿›è¡Œä¸ªæ€§åŒ–
- è¯­è¨€ä¸“ä¸šä¸”æ˜“äºç†è§£
"""
        else:
            prompt = role.system_prompt
            
        return prompt
    
    def _call_gemini_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨Gemini API"""
        try:
            if not self.gemini_client:
                return None
                
            response = self.gemini_client.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=2048,
                    temperature=0.7,
                )
            )
            
            if response and response.text:
                return response.text.strip()
                
        except Exception as e:
            self.logger.error(f"Gemini API call failed: {e}")
            
        return None
    
    def _validate_response_quality(self, response: str, context: Dict[str, Any]) -> bool:
        """éªŒè¯AIå“åº”è´¨é‡"""
        if not response or len(response) < 100:
            return False
            
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æœªæ›¿æ¢çš„å˜é‡
        if '[user_system_name]' in response or '[user_core_principle]' in response:
            return False
            
        # æ£€æŸ¥ä¸ªæ€§åŒ–ç¨‹åº¦
        user_system_name = context.get('user_system_name', '')
        if user_system_name and user_system_name not in response:
            return False
            
        return True
    
    def _generate_enhanced_fallback(self, role_id: str, context: Dict[str, Any], 
                                  personalization_data: Dict[str, Any]) -> str:
        """
        ğŸ”§ ç”Ÿæˆé«˜è´¨é‡çš„ä¸ªæ€§åŒ–é™çº§å†…å®¹
        """
        if role_id != 'assistant':
            role = self.roles.get(role_id)
            if role and role.fallback_responses:
                return role.fallback_responses.get('technical_issue', 
                    "ç³»ç»Ÿæ­£åœ¨ä¸ºæ‚¨å‡†å¤‡ä¸ªæ€§åŒ–å†…å®¹ï¼Œè¯·ç¨å€™...")
        
        # ğŸ”§ ä¸ºåŠ©ç†è§’è‰²ç”Ÿæˆå®Œç¾çš„ä¸ªæ€§åŒ–é™çº§å†…å®¹
        user_system_name = context.get('user_system_name', 'é«˜çº§å†³ç­–å®‰å…¨ç³»ç»Ÿ')
        user_core_principle = context.get('user_core_principle', 'æƒå¨è¶Šå¼ºï¼Œè¶Šè¦éªŒè¯')
        
        # åˆ†æç”¨æˆ·å†³ç­–ç±»å‹
        user_decisions = context.get('user_decisions', {})
        decision_style = self._analyze_decision_style(user_decisions)
        
        fallback_content = f"""
## ğŸ¯ {user_system_name}

### æ ¸å¿ƒæŒ‡å¯¼åŸåˆ™
> **{user_core_principle}**

### ğŸ“‹ å››ç»´éªŒè¯æ¸…å•

#### 1. èº«ä»½éªŒè¯ç»´åº¦
- âœ… è¦æ±‚å…·ä½“çš„èƒ½åŠ›è¯æ˜ï¼Œè€Œéä»…å‡­å¤´è¡”
- âœ… éªŒè¯è¿‡å¾€æˆåŠŸæ¡ˆä¾‹çš„çœŸå®æ€§
- âœ… å¯»æ‰¾ç¬¬ä¸‰æ–¹ç‹¬ç«‹éªŒè¯

#### 2. ä¸šç»©éªŒè¯ç»´åº¦  
- âœ… è¦æ±‚å®Œæ•´çš„ä¸šç»©æŠ¥å‘Šå’Œå®¡è®¡è¯æ˜
- âœ… å…³æ³¨ä¸šç»©çš„æŒç»­æ€§å’Œç¨³å®šæ€§
- âœ… åˆ†æä¸šç»©èƒŒåçš„å¸‚åœºç¯å¢ƒå› ç´ 

#### 3. ç­–ç•¥éªŒè¯ç»´åº¦
- âœ… æ‹’ç»"å•†ä¸šæœºå¯†"ä¸ºç”±çš„ç­–ç•¥éšç’
- âœ… è¦æ±‚ç­–ç•¥çš„é€»è¾‘åˆç†æ€§è§£é‡Š
- âœ… è¯„ä¼°ç­–ç•¥çš„é£é™©æ”¶ç›Šæ¯”

#### 4. ç‹¬ç«‹éªŒè¯ç»´åº¦
- âœ… å¯»æ‰¾çœŸæ­£ç‹¬ç«‹çš„ç¬¬ä¸‰æ–¹æ„è§
- âœ… é¿å…åˆ©ç›Šç›¸å…³è€…çš„"æ¨è"
- âœ… è¿›è¡Œå¤šæ¸ é“ä¿¡æ¯äº¤å‰éªŒè¯

### ğŸš¨ ä¸ªæ€§åŒ–é¢„è­¦ç³»ç»Ÿ

**åŸºäºæ‚¨çš„{decision_style}ç‰¹å¾ï¼Œç‰¹åˆ«æ³¨æ„ï¼š**

{self._get_personalized_warnings(decision_style)}

### ğŸ›¡ï¸ å®æ–½æŒ‡å¯¼

1. **æ—¥å¸¸å†³ç­–æ£€æŸ¥**ï¼šæ¯ä¸ªé‡è¦å†³ç­–å‰è¿è¡Œå››ç»´éªŒè¯
2. **å›¢é˜Ÿå…±äº«**ï¼šå°†æ­¤ç³»ç»Ÿåˆ†äº«ç»™å†³ç­–å›¢é˜Ÿæˆå‘˜
3. **å®šæœŸå›é¡¾**ï¼šæ¯æœˆå›é¡¾å†³ç­–è´¨é‡ï¼Œä¼˜åŒ–ç³»ç»Ÿ
4. **æŒç»­å­¦ä¹ **ï¼šæ”¶é›†æ–°çš„è®¤çŸ¥åè¯¯æ¡ˆä¾‹ï¼Œå®Œå–„ç³»ç»Ÿ

### ğŸ¯ æ ¸å¿ƒä»·å€¼
è¿™ä¸ªç³»ç»Ÿå°†å¸®åŠ©æ‚¨åœ¨é¢ä¸´ç±»ä¼¼éº¦é“å¤«å¼çš„"å®Œç¾"æŠ•èµ„æœºä¼šæ—¶ï¼Œä¿æŒç†æ€§å’Œè­¦è§‰ï¼Œé¿å…è¢«æƒå¨å…‰ç¯è¿·æƒ‘ã€‚

**è®°ä½ï¼š{user_core_principle}**
"""
        
        return fallback_content
    
    def _analyze_decision_style(self, user_decisions: Dict[str, Any]) -> str:
        """åˆ†æç”¨æˆ·å†³ç­–é£æ ¼"""
        final_decision = str(user_decisions.get('decision_final', ''))
        
        if 'å…¨åŠ›æŠ•å…¥' in final_decision or 'å¤§èƒ†' in final_decision:
            return "æ¿€è¿›å‹å†³ç­–è€…"
        elif 'æ‹’ç»' in final_decision or 'æš‚ä¸æŠ•èµ„' in final_decision:
            return "è°¨æ…å‹å†³ç­–è€…"
        else:
            return "å¹³è¡¡å‹å†³ç­–è€…"
    
    def _get_personalized_warnings(self, decision_style: str) -> str:
        """è·å–ä¸ªæ€§åŒ–é¢„è­¦å†…å®¹"""
        warnings = {
            "æ¿€è¿›å‹å†³ç­–è€…": """
- âš ï¸ **è¿‡åº¦è‡ªä¿¡é™·é˜±**ï¼šæ‚¨çš„æœæ–­ä¼˜åŠ¿å¯èƒ½å˜æˆç›²ç›®è‡ªä¿¡
- âš ï¸ **é€Ÿåº¦å‹åŠ›**ï¼šé¿å…å› è¿½æ±‚æ•ˆç‡è€Œè·³è¿‡éªŒè¯æ­¥éª¤
- âš ï¸ **æœºä¼šæˆæœ¬ç„¦è™‘**ï¼šä¸è¦å› ä¸ºå®³æ€•é”™è¿‡è€Œé™ä½æ ‡å‡†
""",
            "è°¨æ…å‹å†³ç­–è€…": """
- âš ï¸ **è¿‡åº¦è°¨æ…**ï¼šä¸è¦å› ä¸ºå¤ªå¤šéªŒè¯è€Œé”™å¤±çœŸæ­£çš„æœºä¼š
- âš ï¸ **åˆ†æç˜«ç—ª**ï¼šé¿å…æ— ä¼‘æ­¢çš„ä¿¡æ¯æ”¶é›†è€Œä¸å†³ç­–
- âš ï¸ **æƒå¨ä¾èµ–**ï¼šè°¨æ…çš„äººæ›´å®¹æ˜“è¿‡åº¦ä¿¡ä»»ä¸“å®¶æ„è§
""",
            "å¹³è¡¡å‹å†³ç­–è€…": """
- âš ï¸ **æ¨¡ç³Šåœ°å¸¦**ï¼šåœ¨æ¨¡æ£±ä¸¤å¯æ—¶ï¼Œå€¾å‘äºç³»ç»Ÿæ€§éªŒè¯
- âš ï¸ **ä¸€è‡´æ€§åè¯¯**ï¼šé¿å…ä¸ºäº†ä¿æŒä¸€è‡´è€Œå¿½ç•¥æ–°ä¿¡æ¯
- âš ï¸ **ç¤¾ä¼šè¯æ˜ä¾èµ–**ï¼šä¸è¦å› ä¸º"å¤§å®¶éƒ½åœ¨åš"è€Œé™ä½æ ‡å‡†
"""
        }
        
        return warnings.get(decision_style, warnings["å¹³è¡¡å‹å†³ç­–è€…"])


class PersonalizationAnalyzer:
    """
    ğŸ”§ ä¸ªæ€§åŒ–åˆ†æå™¨ - åˆ†æç”¨æˆ·ç‰¹å¾å’Œåå¥½
    """
    
    def analyze_user_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·ä¸Šä¸‹æ–‡ï¼Œæå–ä¸ªæ€§åŒ–ç‰¹å¾"""
        user_decisions = context.get('user_decisions', {})
        
        # åˆ†æå†³ç­–é£æ ¼
        decision_style = self._analyze_decision_style(user_decisions)
        
        # åˆ†æé£é™©åå¥½
        risk_preference = self._analyze_risk_preference(user_decisions)
        
        # æå–å…³é”®å†³ç­–
        key_decision = user_decisions.get('decision_final', 'æœªçŸ¥å†³ç­–')
        
        return {
            'decision_style': decision_style,
            'risk_preference': risk_preference,
            'key_decision': key_decision,
            'personalization_level': 'high'
        }
    
    def _analyze_decision_style(self, decisions: Dict[str, Any]) -> str:
        """åˆ†æå†³ç­–é£æ ¼"""
        final_decision = str(decisions.get('decision_final', ''))
        
        if 'å…¨åŠ›æŠ•å…¥' in final_decision:
            return "æ¿€è¿›å‹"
        elif 'æ‹’ç»' in final_decision or 'æš‚ä¸' in final_decision:
            return "è°¨æ…å‹"
        else:
            return "å¹³è¡¡å‹"
    
    def _analyze_risk_preference(self, decisions: Dict[str, Any]) -> str:
        """åˆ†æé£é™©åå¥½"""
        decision_reasons = str(decisions.get('decision_reasoning', ''))
        
        if 'é£é™©' in decision_reasons and 'æ§åˆ¶' in decision_reasons:
            return "é£é™©æ§åˆ¶"
        elif 'æœºä¼š' in decision_reasons and 'æ”¶ç›Š' in decision_reasons:
            return "æ”¶ç›Šå¯¼å‘"
        else:
            return "é€‚ä¸­å¹³è¡¡"


class AIRole:
    """AIè§’è‰²å®šä¹‰"""
    def __init__(self, role_id: str, config: Dict[str, Any]):
        self.role_id = role_id
        self.name = config.get('name', '')
        self.system_prompt = config.get('system_prompt', '')
        self.fallback_responses = config.get('fallback_responses', {})


# å…¨å±€AIå¼•æ“å®ä¾‹
ai_engine = EnhancedAIEngine()
